The project aims to create an innovative smart text reading solution specifically designed to cater to the needs of individuals living with visual impairments. Through the utilization of image processing techniques facilitated by the capabilities of OpenCV libraries, the system aims to seamlessly capture images, extract textual content through Optical Character Recognition (OCR) and subsequently translate it into comprehensible speech output through Text-to-Speech (TTS) engines. Prominent features include real-time text extraction, user-friendly language customization options and broad compatibility with various formats of black and white printed or handwritten text.

TECH STACK 

OpenCV: Libraries utilized for image processing tasks such as capturing images and extracting text. 

Tesseract OCR: Employed to convert printed text into machine-readable text by extracting text from images. 

TTS (Text-to-Speech) Engine: Technology utilized to convert the extracted text into speech output, allowing users to hear the content. 

Python: A programming language commonly used for developing applications and scripting tasks, the primary language for implementing the project's functionalities. 

Camera: Hardware component integrated for capturing images. 

Audio Output Device (Headphones/Speakers): A hardware component used to deliver the synthesized speech output to users. 
